import pandas as pd
import requests
import json
import os
import time
import urllib3
import warnings
from io import StringIO
import re
import math 
import yfinance as yf

# --- 1. åŸºç¤è¨­å®š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)

# è¨­å®šè¦æŠ“å–çš„ ETF æ¸…å–®
target_etfs = [
    # --- ä¸»å‹•å¼ ETF (Active) ---
    {"id": 1, "ticker": "00981A", "name": "ä¸»å‹•çµ±ä¸€å°è‚¡æˆé•·", "type": "active", "manager": "çµ±ä¸€æŠ•ä¿¡"}, 
    {"id": 2, "ticker": "00980A", "name": "ä¸»å‹•é‡æ‘è‡ºç£å„ªé¸", "type": "active", "manager": "é‡æ‘æŠ•ä¿¡"}, 
    {"id": 4, "ticker": "00985A", "name": "ä¸»å‹•é‡æ‘å°è‚¡50", "type": "active", "manager": "é‡æ‘æŠ•ä¿¡"}, 
    {"id": 5, "ticker": "00984A", "name": "ä¸»å‹•å®‰è¯å°ç£é«˜æ¯", "type": "active", "manager": "å®‰è¯æŠ•ä¿¡"}, 
    {"id": 7, "ticker": "00992A", "name": "ä¸»å‹•ç¾¤ç›Šç§‘æŠ€å‰µæ–°", "type": "active", "manager": "ç¾¤ç›ŠæŠ•ä¿¡"},
    {"id": 6, "ticker": "00999", "name": "ä¸»å‹•å¯Œé‚¦æ–°æ˜Ÿçˆ†ç™¼", "type": "active", "manager": "å¯Œé‚¦æŠ•ä¿¡"},
    {"id": 8, "ticker": "00994A", "name": "ä¸»å‹•ç¬¬ä¸€é‡‘å°è‚¡è¶¨å‹¢å„ªé¸", "type": "active", "manager": "ç¬¬ä¸€é‡‘æŠ•ä¿¡"},
    {"id": 9, "ticker": "00995A", "name": "ä¸»å‹•ä¸­ä¿¡å°ç£å“è¶Š", "type": "active", "manager": "ä¸­åœ‹ä¿¡è¨—æŠ•ä¿¡"},
    {"id": 10, "ticker": "00993A", "name": "ä¸»å‹•å®‰è¯å°ç£", "type": "active", "manager": "å®‰è¯æŠ•ä¿¡"},
    
    # æ–°å¢çš„æ¸…å–®
    {"id": 20, "ticker": "00982A", "name": "ä¸»å‹•ç¾¤ç›Šå°ç£å¼·æ£’", "type": "active", "manager": "ç¾¤ç›ŠæŠ•ä¿¡"},
    {"id": 21, "ticker": "00986A", "name": "ä¸»å‹•å°æ–°é¾é ­æˆé•·", "type": "active", "manager": "å°æ–°æŠ•ä¿¡"},
    {"id": 22, "ticker": "00987A", "name": "ä¸»å‹•å°æ–°ç§‘æŠ€é«˜æ¯", "type": "active", "manager": "å°æ–°æŠ•ä¿¡"},
    {"id": 23, "ticker": "00983A", "name": "ä¸»å‹•ä¸­ä¿¡ARKå‰µæ–°", "type": "active", "manager": "ä¸­ä¿¡æŠ•ä¿¡"},
    {"id": 24, "ticker": "00988A", "name": "ä¸»å‹•çµ±ä¸€å…¨çƒå‰µæ–°", "type": "active", "manager": "çµ±ä¸€æŠ•ä¿¡"},
    {"id": 25, "ticker": "00989A", "name": "ä¸»å‹•æ‘©æ ¹ç¾åœ‹ç§‘æŠ€", "type": "active", "manager": "æ‘©æ ¹æŠ•ä¿¡"},
    {"id": 26, "ticker": "00990A", "name": "ä¸»å‹•å…ƒå¤§AIæ–°ç¶“æ¿Ÿ", "type": "active", "manager": "å…ƒå¤§æŠ•ä¿¡"},
    {"id": 27, "ticker": "00991A", "name": "ä¸»å‹•å¾©è¯æœªä¾†50", "type": "active", "manager": "å¾©è¯æŠ•ä¿¡"},

    # --- è¢«å‹•å¼ ETF (Passive) ---
    {"id": 3, "ticker": "0050", "name": "å…ƒå¤§å°ç£50", "type": "passive", "index": "å°ç£50æŒ‡æ•¸"}, 
    {"id": 101, "ticker": "00878", "name": "åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯", "type": "passive", "index": "ESGæ°¸çºŒé«˜è‚¡æ¯"},
    {"id": 102, "ticker": "0056", "name": "å…ƒå¤§é«˜è‚¡æ¯", "type": "passive", "index": "è‡ºç£é«˜è‚¡æ¯æŒ‡æ•¸"},
    {"id": 103, "ticker": "00929", "name": "å¾©è¯å°ç£ç§‘æŠ€å„ªæ¯", "type": "passive", "index": "ç§‘æŠ€å„ªæ¯æŒ‡æ•¸"},
    {"id": 108, "ticker": "00891", "name": "ä¸­ä¿¡é—œéµåŠå°é«”", "type": "passive", "index": "ICEåŠå°é«”æŒ‡æ•¸"},
    {"id": 109, "ticker": "0052", "name": "å¯Œé‚¦ç§‘æŠ€", "type": "passive", "index": "è³‡è¨Šç§‘æŠ€æŒ‡æ•¸"},
    {"id": 111, "ticker": "006208", "name": "å¯Œé‚¦å°50", "type": "passive", "index": "å°ç£50æŒ‡æ•¸"},
    {"id": 112, "ticker": "00636", "name": "åœ‹æ³°ä¸­åœ‹A50", "type": "passive", "index":"å¯Œæ™‚ä¸­åœ‹A50æŒ‡æ•¸"},
    {"id": 113, "ticker": "00646", "name": "å…ƒå¤§S&P500", "type": "passive", "index": "S&P500æŒ‡æ•¸"},
    {"id": 114, "ticker": "00738U", "name": "åœ’å¤§é“ç“Šç™½éŠ€", "type": "passive", "index": "é“ç“Šç™½éŠ€ERæŒ‡æ•¸"},
    {"id": 115, "ticker": "00919", "name": "ç¾¤ç›Šå°ç£ç²¾é¸é«˜æ¯", "type": "passive", "index": "ç‰¹é¸è‡ºç£ç²¾é¸é«˜æ¯æŒ‡æ•¸"},
    {"id": 116, "ticker": "00918", "name": "å…ƒå¤§å°ç£é«˜æ¯ä½æ³¢", "type": "passive", "index": "é«˜æ¯ä½æ³¢æŒ‡æ•¸"},
    {"id": 110, "ticker": "00679B", "name": "å…ƒå¤§ç¾å‚µ20å¹´", "type": "passive", "index": "ç¾å‚µ20å¹´æŒ‡æ•¸"}
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://www.moneydj.com/'
}

# --- å·¥å…·å‡½å¼ ---

def get_number_from_text(text):
    """å¾å­—ä¸²ä¸­æå–æµ®é»æ•¸ï¼Œä¸¦éæ¿¾ NaNã€åƒåˆ†ä½é€—è™Ÿã€ç™¾åˆ†æ¯”ç¬¦è™Ÿ"""
    try:
        if pd.isna(text) or text == "" or str(text).strip() == "-":
            return None
        clean_text = re.sub(r'[%, ]', '', str(text)) # ç§»é™¤ %, é€—è™Ÿ, ç©ºæ ¼
        val = float(clean_text)
        if math.isnan(val) or math.isinf(val): return 0.0
        return val
    except:
        return None

# --- 3. æ–°å¢ï¼šè®€å–èˆŠè³‡æ–™ ---
def load_previous_data():
    """è®€å–ç¾æœ‰çš„ public/etf_data.json ä»¥ä¾¿æ¯”å°æŒè‚¡"""
    path = 'public/etf_data.json'
    if os.path.exists(path):
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

# --- 4. æ–°å¢ï¼šè¨ˆç®—æŒè‚¡è®ŠåŒ– ---
def compare_holdings(new_holdings, old_holdings):
    """
    æ¯”å°æ–°èˆŠæŒè‚¡ï¼Œè¨ˆç®—å¢æ¸›
    new_holdings: [{"stock": "å°ç©é›»", "percent": 50.0}, ...]
    old_holdings: åŒä¸Šï¼Œä¾†è‡ªä¸Šæ¬¡å­˜æª”
    """
    # å°‡èˆŠæŒè‚¡è½‰ç‚ºå­—å…¸ä»¥ä¾¿æŸ¥è©¢: {'å°ç©é›»': 50.0, 'è¯ç™¼ç§‘': 10.0}
    old_map = {item['stock']: item['percent'] for item in old_holdings}
    
    processed_holdings = []
    
    for stock in new_holdings:
        name = stock['stock']
        curr_pct = stock['percent']
        
        # é è¨­è®ŠåŒ–å­—ä¸²
        change_str = "-"
        change_val = 0.0
        
        if name in old_map:
            old_pct = old_map[name]
            diff = curr_pct - old_pct
            
            # è¨­å®šé–€æª»ï¼Œå¾®å°èª¤å·®å¿½ç•¥
            if abs(diff) > 0.001:
                if diff > 0:
                    change_str = f"ğŸ”º{diff:.2f}%" # å¢åŠ 
                else:
                    change_str = f"ğŸ”»{abs(diff):.2f}%" # æ¸›å°‘
                change_val = diff
        else:
            change_str = "ğŸ†•æ–°é€²" # èˆŠè³‡æ–™æ²’æœ‰ï¼Œæ–°è³‡æ–™æœ‰
            change_val = curr_pct
            
        processed_holdings.append({
            "stock": name,
            "percent": curr_pct,
            "change": change_str,      # é¡¯ç¤ºç”¨çš„å­—ä¸² (e.g., ğŸ”º0.5%)
            "changeVal": change_val    # æ•¸å€¼ï¼Œæ–¹ä¾¿ä»¥å¾Œæ’åºç”¨
        })
        
    return processed_holdings

# --- 1. æŠ“å–åŸºæœ¬è³‡æ–™ (æˆç«‹æ—¥æœŸã€é…æ¯é »ç‡) [æ–°å¢åŠŸèƒ½] ---
def fetch_basic_profile(ticker_id):
    """æŠ“å– Basic0004 é é¢çš„åŸºæœ¬è³‡æ–™"""
    url = f"https://www.moneydj.com/ETF/X/Basic/Basic0004.xdjhtm?etfid={ticker_id}"
    
    profile = {
        "foundedDate": "N/A",      # æˆç«‹æ—¥æœŸ
        "dividendFreq": "N/A",     # é…æ¯é »ç‡
        "managerFee": "N/A",       # ç¶“ç†è²»
        "custodian": "N/A"         # ä¿ç®¡éŠ€è¡Œ
    }
    
    try:
        resp = requests.get(url, headers=HEADERS, timeout=10, verify=False)
        resp.encoding = 'utf-8'
        
        if "æŸ¥ç„¡" in resp.text:
            return profile

        tables = pd.read_html(StringIO(resp.text))
        
        for table in tables:
            # éæ­·è¡¨æ ¼ä¸­çš„æ¯ä¸€å€‹ row
            for index, row in table.iterrows():
                row_list = [str(x).strip() for x in row]
                
                for i, cell_text in enumerate(row_list):
                    # 1. æŠ“å–æˆç«‹æ—¥æœŸ
                    if "æˆç«‹æ—¥æœŸ" in cell_text:
                        if i + 1 < len(row_list):
                            raw_date = row_list[i+1]
                            # ä½¿ç”¨ Regex æå– YYYY/MM/DDï¼Œéæ¿¾æ‰å¾Œé¢æ‹¬è™Ÿæ–‡å­— e.g. (å·²æˆç«‹1å¹´)
                            match = re.search(r'\d{4}/\d{2}/\d{2}', raw_date)
                            if match:
                                profile["foundedDate"] = match.group(0)
                            else:
                                profile["foundedDate"] = raw_date
                    
                    # 2. æŠ“å–é…æ¯é »ç‡
                    elif "é…æ¯é »ç‡" in cell_text:
                        if i + 1 < len(row_list):
                            profile["dividendFreq"] = row_list[i+1]

                    # 3. æŠ“å–ä¿ç®¡éŠ€è¡Œ
                    elif "ä¿ç®¡æ©Ÿæ§‹" in cell_text or "ä¿ç®¡éŠ€è¡Œ" in cell_text:
                         if i + 1 < len(row_list):
                            profile["custodian"] = row_list[i+1]
        
        # é™¤éŒ¯å°å‡º
        if profile["foundedDate"] != "N/A":
            print(f"      ğŸ“ åŸºæœ¬è³‡æ–™: æˆç«‹ {profile['foundedDate']}, é…æ¯ {profile['dividendFreq']}")
        return profile

    except Exception as e:
        # print(f"      âš ï¸ åŸºæœ¬è³‡æ–™æŠ“å–å¤±æ•—: {e}") # é™¤éŒ¯ç”¨ï¼Œä¸æƒ³æ´—ç‰ˆå¯è¨»è§£
        return profile

# --- 2. æŠ“å–æ·¨å€¼ (NAV) ---
def fetch_nav(ticker_id):
    urls = [
        f"https://www.moneydj.com/ETF/X/Basic/Basic0003.xdjhtm?etfid={ticker_id}", 
        f"https://www.moneydj.com/ETF/X/Basic/Basic0004.xdjhtm?etfid={ticker_id}"
    ]
    
    for url in urls:
        try:
            resp = requests.get(url, headers=HEADERS, timeout=10, verify=False)
            resp.encoding = 'utf-8'
            if "æŸ¥ç„¡" in resp.text: continue
            
            tables = pd.read_html(StringIO(resp.text))
            for table in tables:
                for index, row in table.iterrows():
                    row_str = "".join([str(x) for x in row])
                    if "æ·¨å€¼" in row_str:
                        for cell in row:
                            val = get_number_from_text(cell)
                            # æ·¨å€¼éæ¿¾å™¨ (5 ~ 2000)
                            if val and 5.0 < val < 2000.0:
                                return val
        except:
            continue
    return 0.0

# --- 3. æŠ“å–ç¸¾æ•ˆ ---
def fetch_performance_metrics(ticker_id):
    url_0008 = f"https://www.moneydj.com/ETF/X/Basic/Basic0008.xdjhtm?etfid={ticker_id}"
    data = {"ytd": 0.0, "weekly": 0.0}
    
    try:
        resp = requests.get(url_0008, headers=HEADERS, timeout=10, verify=False)
        resp.encoding = 'utf-8'
        tables = pd.read_html(StringIO(resp.text))
        target_table = None
        
        for table in tables:
            cols = "".join([str(c) for c in table.columns])
            if "ä¸€é€±" in cols and ("å…­å€‹æœˆ" in cols or "æˆç«‹" in cols or "ä¸‰å€‹æœˆ" in cols):
                target_table = table
                break
        
        if target_table is not None:
            row_idx = -1
            for idx, row in target_table.iterrows():
                row_str = str(row[0])
                if "æ·¨å€¼" in row_str or "å¸‚åƒ¹" in row_str: 
                    row_idx = idx
                    break
            
            if row_idx == -1 and len(target_table) > 0: row_idx = 0

            if row_idx != -1:
                # æŠ“é€±ç¸¾æ•ˆ
                if "ä¸€é€±" in target_table.columns:
                    val = get_number_from_text(target_table.loc[row_idx, "ä¸€é€±"])
                    if val is not None: data["weekly"] = val
                
                # æŠ“ YTD
                if "ä»Šå¹´ä»¥ä¾†" in target_table.columns:
                    val = get_number_from_text(target_table.loc[row_idx, "ä»Šå¹´ä»¥ä¾†"])
                    if val is not None: data["ytd"] = val
                elif "æˆç«‹æ—¥" in target_table.columns: # é‡å°æ–° ETF
                    val = get_number_from_text(target_table.loc[row_idx, "æˆç«‹æ—¥"])
                    if val is not None: data["ytd"] = val
                elif "æˆç«‹è‡³ä»Š" in target_table.columns:
                     val = get_number_from_text(target_table.loc[row_idx, "æˆç«‹è‡³ä»Š"])
                     if val is not None: data["ytd"] = val
                     
                print(f"      ğŸ“ˆ ç¸¾æ•ˆæ•¸æ“š: é€± {data['weekly']}%, YTD/æˆç«‹ {data['ytd']}%")
                return data
    except Exception:
        pass

    # å‚™ç”¨ï¼šBasic0006
    url_0006 = f"https://www.moneydj.com/ETF/X/Basic/Basic0006.xdjhtm?etfid={ticker_id}"
    try:
        resp = requests.get(url_0006, headers=HEADERS, timeout=10, verify=False)
        resp.encoding = 'utf-8'
        clean_text = re.sub(r'<[^>]+>', ' ', resp.text)
        
        match_week = re.search(r'é€±.*?(-?\d+\.\d+)%', clean_text)
        if match_week: data["weekly"] = float(match_week.group(1))
        
        match_ytd = re.search(r'ä»Šå¹´ä»¥ä¾†.*?(-?\d+\.\d+)%', clean_text)
        if match_ytd: data["ytd"] = float(match_ytd.group(1))
    except:
        pass
        
    return data

# --- 4. æŠ“å–æŒè‚¡ ---
def fetch_holdings(ticker_id):
    # æ‰‹å‹•æ³¨å…¥ (å¦‚æœéœ€è¦ç‰¹å®š ETF çš„æ•¸æ“šå¯ä¿ç•™ï¼Œä¸éœ€è¦å¯è¨»è§£)
    if "00984A" in ticker_id:
        return [{"stock": "å°ç©é›»(2330)", "percent": 5.03, "change": "-"}, {"stock": "å¯Œé‚¦é‡‘(2881)", "percent": 3.81, "change": "-"}, {"stock": "åœ‹æ³°é‡‘(2882)", "percent": 3.76, "change": "-"}, {"stock": "ä¸­ä¿¡é‡‘(2891)", "percent": 3.53, "change": "-"}, {"stock": "å»£é”(2382)", "percent": 3.32, "change": "-"}]

    url = f"https://www.moneydj.com/ETF/X/Basic/Basic0007.xdjhtm?etfid={ticker_id}"
    print(f"   ğŸ” æ­£åœ¨æŠ“å–: {ticker_id}")
    
    try:
        resp = requests.get(url, headers=HEADERS, timeout=10, verify=False)
        resp.encoding = 'utf-8'
        tables = pd.read_html(StringIO(resp.text))
        target_table = None
        for table in tables:
            cols = "".join([str(c) for c in table.columns])
            if ("åç¨±" in cols or "è‚¡ç¥¨" in cols or "å€‹è‚¡" in cols) and ("æ¯”" in cols or "%" in cols):
                target_table = table
                break
        
        if target_table is None:
            # print(f"      âŒ æ‰¾ä¸åˆ°æŒè‚¡è¡¨æ ¼")
            return []

        holdings = []
        target_table.columns = [str(c).strip() for c in target_table.columns]
        
        name_col = next((c for c in target_table.columns if "åç¨±" in c or "è‚¡ç¥¨" in c or "å€‹è‚¡" in c), None)
        percent_col = next((c for c in target_table.columns if "%" in c or "æ¯”" in c), None)

        if name_col and percent_col:
            for index, row in target_table.head(10).iterrows():
                name = str(row[name_col])
                pct = str(row[percent_col])
                if name == "nan" or name == "": continue
                val = get_number_from_text(pct)
                if val is None: val = 0.0
                holdings.append({"stock": name, "percent": val, "change": "-"})
        
        print(f"      âœ… æŠ“åˆ° {len(holdings)} æª”æŒè‚¡")
        return holdings
    except:
        return []

 # --- 5. æ–°å¢ï¼šæŠ“å–çœŸå¯¦æ­·å²è‚¡åƒ¹ (Yahoo Finance) ---
def fetch_real_chart(ticker_id):
    """
    å˜—è©¦å¾ Yahoo Finance æŠ“å–è¿‘ 6 å€‹æœˆçš„æ­·å²è‚¡åƒ¹
    å›å‚³æ ¼å¼: [{"month": "12/01", "return": 15.2}, ...]
    """
    try:
        # ä¸‹è¼‰æ­·å²è³‡æ–™ï¼Œperiod="6mo" ä»£è¡¨åŠå¹´
        # interval="1wk" ä»£è¡¨ä»¥ã€Œé€±ã€ç‚ºå–®ä½ (é¿å…æ•¸æ“šé»å¤ªå¤š JSON æª”æ¡ˆå¤ªå¤§)
        df = yf.Ticker(ticker_id).history(period="6mo", interval="1wk")
        
        if df.empty or len(df) < 2:
            return None # æŠ“ä¸åˆ°è³‡æ–™ï¼Œå›å‚³ None è®“ä¸»ç¨‹å¼åˆ‡æ›å›æ¨¡æ“¬æ¨¡å¼

        chart_data = []
        for date, row in df.iterrows():
            # æ ¼å¼åŒ–æ—¥æœŸï¼Œä¾‹å¦‚ "01/05"
            date_str = date.strftime('%m/%d')
            # å–æ”¶ç›¤åƒ¹ (Close)
            price = row['Close']
            
            # é€™è£¡æˆ‘å€‘ç›´æ¥å­˜ã€Œè‚¡åƒ¹(NAV)ã€ï¼Œå‰ç«¯é¡¯ç¤ºæœƒæ›´ç›´è§€
            chart_data.append({
                "month": date_str, 
                "return": round(price, 2)
            })
            
        return chart_data
    except Exception as e:
        print(f"      âš ï¸ Yahoo Finance æŠ“å–å¤±æ•—: {e}")
        return None       

# --- ä¸»ç¨‹å¼ ---
print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ...ä¸¦é€²è¡ŒæŒè‚¡æ¯”å°")

# 1. å…ˆè®€å–èˆŠè³‡æ–™ (æ­·å²ç´€éŒ„)
previous_data_list = load_previous_data()
# å»ºç«‹å¿«é€ŸæŸ¥è©¢è¡¨: { "00981A": [æŒè‚¡list], "0050": [æŒè‚¡list] }
previous_map = { item['ticker']: item.get('holdings', []) for item in previous_data_list }

output_data = []

for etf in target_etfs:
    raw_ticker = etf['ticker'].replace(".TW", "")
    target_id = f"{raw_ticker}.TW"
    
    print(f"\n[{etf['id']}] è™•ç†ä¸­: {etf['name']}")
    
    # æŠ“å–å„é …è³‡æ–™
    # æ³¨æ„ï¼šé€™è£¡ fetch_holdings æŠ“å›ä¾†çš„æ˜¯ã€Œç´”æ·¨å€¼ã€ï¼Œchange é‚„æ˜¯ "-"
    holdings_raw = fetch_holdings(target_id) 
    nav = fetch_nav(target_id)
    perf = fetch_performance_metrics(target_id)
    profile = fetch_basic_profile(target_id)
    
    # â˜…â˜…â˜… é—œéµæ­¥é©Ÿï¼šé€²è¡ŒæŒè‚¡æ¯”å° â˜…â˜…â˜…
    # å¾èˆŠè³‡æ–™ä¸­æ‰¾å‡ºé€™æª” ETF ä¸Šæ¬¡çš„æŒè‚¡
    old_holdings_for_this_etf = previous_map.get(etf['ticker'], [])
    # è¨ˆç®—è®ŠåŒ–
    holdings_with_change = compare_holdings(holdings_raw, old_holdings_for_this_etf)
    
    ytd = perf["ytd"]
    weekly = perf["weekly"]
    
    status = "MoneyDJ çœŸå¯¦æ•¸æ“š"
    if nav == 0 and ytd == 0: status = "æŸ¥ç„¡æ•¸æ“š"


    # --- èµ°å‹¢åœ–é‚è¼¯ (å‡ç´šç‰ˆ) ---
    chart_data = []
    
    # 1. å„ªå…ˆå˜—è©¦æŠ“å–ã€ŒçœŸå¯¦ã€æ­·å²è‚¡åƒ¹
    real_chart = fetch_real_chart(target_id)
    
    if real_chart:
        print(f"      ğŸ“ˆ æˆåŠŸæŠ“å–çœŸå¯¦èµ°å‹¢åœ– ({len(real_chart)} é»)")
        chart_data = real_chart
        # å¦‚æœæœ‰çœŸå¯¦è‚¡åƒ¹ï¼Œæˆ‘å€‘æŠŠæœ€æ–°çš„è‚¡åƒ¹ä¹Ÿæ›´æ–°ä¸€ä¸‹ NAV (é€šå¸¸ Yahoo æ›´æ–°ç¨æ…¢ï¼Œä½†å¯ä½œåƒè€ƒ)
        # nav = real_chart[-1]['return'] 
    
    # 2. å¦‚æœæŠ“ä¸åˆ° (ä¾‹å¦‚æ˜¨å¤©æ‰ä¸Šå¸‚ï¼ŒYahooé‚„æ²’å»ºæª”)ï¼Œå‰‡ä½¿ç”¨ã€Œæ¨¡æ“¬ã€ç®—æ³•
    elif ytd != 0:
        print(f"      ğŸ§ª ä½¿ç”¨æ¨¡æ“¬èµ°å‹¢åœ–")
        start_val = nav / (1 + ytd/100) # åæ¨æœŸåˆæ·¨å€¼
        steps = 5
        for i in range(steps + 1):
            # ç·šæ€§æ’å€¼
            val = start_val + (nav - start_val) * (i/steps)
            # ç”¢ç”Ÿ T-5, T-4 é€™ç¨®æ¨™ç±¤
            chart_data.append({"month": f"T-{steps-i}", "return": round(val, 2)})

    # çµ„è£æœ€çµ‚è³‡æ–™

    final_data = {
        **etf,
        "ytdReturn": ytd,
        "weeklyReturn": weekly,
        "latestNav": nav,
        "changeSinceLast": 0,
        "lastDividend": "N/A",
        "exDate": "N/A",
        "fundManager": etf.get("manager", "N/A"),
        "changeStatus": status,
        "holdings": holdings_with_change,  # <--- é€™è£¡æ”¾å…¥è¨ˆç®—å¥½è®ŠåŒ–çš„æŒè‚¡
        "performanceData": chart_data,
        "foundedDate": profile["foundedDate"],
        "dividendFreq": profile["dividendFreq"],
        "custodianBank": profile["custodian"]
    }
    output_data.append(final_data)
    time.sleep(1.0)

# --- æ•¸æ“šæ¸…ç†å·¥å…· ---
def clean_data(data):
    if isinstance(data, list):
        return [clean_data(item) for item in data]
    elif isinstance(data, dict):
        return {k: clean_data(v) for k, v in data.items()}
    elif isinstance(data, float):
        if math.isnan(data) or math.isinf(data):
            return 0.0
        return data
    else:
        return data

cleaned_output = clean_data(output_data)

# --- å­˜æª” ---
if not os.path.exists('public'):
    os.makedirs('public')

file_path = 'public/etf_data.json'
with open(file_path, 'w', encoding='utf-8') as f:
    json.dump(cleaned_output, f, ensure_ascii=False, indent=2)

print(f"\nğŸ‰ æ›´æ–°å®Œæˆï¼æŒè‚¡è®ŠåŒ–å·²è¨ˆç®—å®Œç•¢ã€‚")